{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enoncé du problème\n",
    "\n",
    "L'objectif de ce projet est d'estimer la longueur de câble sous-marin nécessaire pour relier deux côtes $A$ et $B$  en utilisant des simulations conditionnelles.\n",
    "\n",
    "\n",
    "Le câble reposera sur le fond marin dont la profondeur est inconnue.\n",
    "Le segment $[AB]$ est discrétisé par une séquence de (N+1) points. On pose $x_0=A$ et pour $i=1,\\dots,N$, $$x_i=x_0+i\\Delta$$ où $$\\Delta = \\frac{AB}{N}$$ de telle sorte que $x_N=B$.\n",
    "On note $z(x)$ la profondeur du fond marin au point $x$ de telle sorte qu'on pourra estimer la longueur totale de câble nécessaire par la somme des longueurs sur les segments de la discrétisation :\n",
    "\n",
    "$$l=\\sum_{i=1}^N\\sqrt{\\Delta^2+(z(x_i)-z(x_{i-1}))^2}.$$\n",
    "\n",
    "Enfin, notons que l'on dispose d'un ensemble de $n$ observations de la profondeur que l'on supposera situées sur des points de discrétisation $z(x_{j_1}),\\dots,z(x_{j_n})$.\n",
    "\n",
    "\n",
    "On adopte un modèle probabiliste pour la profondeur. On suppose que le vecteur des profondeurs sur les points de discrétisation \n",
    "$\\mathbf{z}=(z(x_0),\\dots,z(x_N))$ est la réalisation d'un vecteur aléatoire gaussien $\\mathbf{Z}=(Z(x_0),\\dots,Z(x_N))$ dont le vecteur d'espérance ne contient qu'une seule valeur $\\mu$ répétée $N+1$ fois et dont la matrice de covariance $\\Sigma$ a pour termes $\\sigma_{ij}$\n",
    "définis par $\\sigma_{ij}=C(|x_i-x_j|)$ où $C$ est une\n",
    "fonction décroissante, traduisant le fait que deux points \n",
    "géographiquement proches ont tendance à avoir des profondeurs plus similaires que deux points éloignés.\n",
    "\n",
    "On supposera que la matrice de covariance ainsi \n",
    "générée est définie-positive (en fait, $C$ sera choisie parmi les fonctions qui, \n",
    "appliquées aux termes d'une matrice de distance, produisent des matrices définie-positives). \n",
    "\n",
    "Si on note $L$ la variable aléatoire donnant la longueur de cable nécessaire : \n",
    "$$L=\\sum_{i=1}^N\\sqrt{\\Delta^2+(Z(x_i)-Z(x_{i-1}))^2},$$\n",
    "un bon estimateur de $L$ est fourni par l'espérance conditionnelle \n",
    "\n",
    "$$L^\\star=E[L|Z(x_{j_1})=z(x_{j_1}),\\dots,Z(x_{j_n})=z(x_{j_n})].$$\n",
    "                                                                              \n",
    "Cependant, cette quantité est difficilement accessible par le calcul. \n",
    "On va donc avoir recours à des\n",
    "simulations conditionnelles. C'est-à-dire que l'on va simuler \n",
    "un nombre $K$ de réalités (disons des réalisations du modèle \n",
    "probabiliste choisi), et sur chacune d'entre elle, \n",
    "la quantité de câble nécessaire sera évaluée. \n",
    "On disposera ainsi d'un échantillon $l_{(1)},\\dots,l_{(K)}$ de \n",
    "longueures simulées. Puis on approchera l'espérance conditionnelle  par \n",
    "$$L^\\star=\\frac{1}{K}\\sum_{k=1}^K l_{(k)}.$$\n",
    "\n",
    "L'objectif de ce projet est donc d'écrire un code permettant \n",
    "d'effectuer cette simulation conditionnelle, puis de l'appliquer \n",
    "au jeu de données fourni et d'en déduire une estimation de la longueur de câble nécessaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions théoriques\n",
    "\n",
    "1. Quel théorème du cours nous autorise-t-il à estimer l'espérance conditionnelle par la moyenne empirique de simulations conditionnelles ?\n",
    "\n",
    "2. Rappeler la loi conditionnelle du vecteur des composantes de $\\mathbf{Z}$ correspondant aux points de discrétisation\n",
    "sans observation, connaissant les valeurs prises par les composantes aux sites d'observation.\n",
    "\n",
    "3. Si $\\mathbf{Y}=(Y_1,\\dots,Y_p)$ est un vecteur de composantes gaussiennes indépendantes, toutes d'espérance nulle et de variance 1, \n",
    "quelle est la loi du vecteur $\\mathbf{Z}=m+R\\mathbf{Y}$ où $R$ est une matrice $p\\times p$ inversible et $m$ est un vecteur de taille $p$ ?\n",
    "\n",
    "4. En déduire un algorithme de simulation conditionnelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "- Par définition, l'espérance conditionnelle est telle que : \n",
    "Soit $Y$ une variable aléatoire intégrable.\n",
    "\n",
    "L'espérance conditionnelle de $Y$ sachant $\\left\\{X=x\\right\\}$ est définie par $$ E(Y|X=x) = \\int_\\mathbb{R} y \\mathbb{P}_{Y|X=x} (dy).$$\n",
    "L'espérance conditionnelle de $Y$ sachant $X$ est la variable aléatoire définie par : $$ E(Y|X) = \\psi(X), \\text{ avec } \\psi(x) = E(Y|X=x).$$\n",
    "\n",
    "- De plus, **la loi forte des grands nombres** nous assure :\n",
    "\n",
    "Soit $(X_n)_{n\\in\\mathbb{N^\\ast}}$ une suite de variables aléatoires indépendantes, de même loi et intégrables, et $m = E(X_n)$ leur espérance. Alors la suite $(M_n)_{n\\in\\mathbb{N^\\ast}}$ définie par $$M_n = \\frac{X_1 + \\ldots + X_n}{n}$$ converge vers $m$, presque sûrement et en moyenne, quand $n$ tend vers l'infini.\n",
    "\n",
    "- On peut donc estimer, d'après la loi forte des grands nombres, $E(Y|X=x) = \\int_\\mathbb{R} y \\mathbb{P}_{Y|X=x}(dy)$ par la moyenne empirique $$M_n(x)=\\frac{1}{n}\\sum_{i=1}^{n}Y_i ,$$ les $(Y_i)$ constituant un échantillon généré tel que $(Y_1,\\ldots,Y_n) \\sim_{i.i.d.}\\mathbb{P}_{Y|X=x}$,où i.i.d signifie indépendant et identiquement distribué.\n",
    "Si $y$ est $\\mathbb{P}_{Y|X}$-intégrable, on a l'assurance que quand $n \\to +\\infty$, $$M_n(x) \\rightarrow E(Y|X=x) = \\int_\\mathbb{R} y \\mathbb{P}_{Y|X=x} (dy) \\text{ p.s.}$$\n",
    "\n",
    "Appliqué à notre problème, on a : les longueurs $l_{(1)},\\dots,l_{(K)}$ mutuellement indépendantes, de même loi et intégrables (car bornées) donc d'après la loi forte des grands nombres, l'espérance conditionnelle peut être estimer par la moyenne empirique de simulations conditionnellles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "On considère le vecteur gaussien $\\mathbf{Z} = (Z(x_0),\\ldots,Z(x_N))$ dont le vecteur d'espérance ne contient qu'une seule valeur $\\mu$ répétée $N+1$ fois et dont la matrice de covariance est notée $\\Sigma$, définie positive. La densité du vecteur $Z$ s'écrit pour $z\\in\\mathbb{R}^{N+1}$ : $$f_Z(z) = \\frac{1}{(2\\pi)^{n/2}\\sqrt{\\det (\\Sigma)}}\\exp \\left(-\\frac{1}{2}(z-\\mu)^t \\Sigma^{-1}(z-\\mu)\\right)$$\n",
    "\n",
    "Soit $0 \\leq k < N$ un entier. \n",
    "On souhaite exprimer $f_{X|T=t}$, la densité conditionnelle de \n",
    "$\\mathbf{X} = (Z(x_0),\\ldots,Z(x_{k-1}))$ sachant que\n",
    "$\\mathbf{T} = (Z(x_k),\\ldots,Z(x_N)) = (z(x_k),\\ldots,z(x_N)) = t$. Il est en effet possible de réordonner le vecteur $\\mathbf{Z}$ pour que les points connus soient ensemble afin de simplifier les calculs par la suite.\n",
    "\n",
    "On sait que $f_Z = f_{X|T=t} f_T$, où $f_T$ est la densité marginale de $T$.\n",
    "On cherche donc à décomposer $f_Z$ de la sorte. On note $m = (m_X,m_T)$ et on remarque que $\\Sigma$ peut se décomposer en blocs : \n",
    "\\begin{equation*} \n",
    "\\Sigma = \\left(\\begin{array}{cc} \n",
    "\\Sigma_X & \\Sigma_{X,T} \\\\\n",
    "\\Sigma_{T,X} & \\Sigma_t \n",
    "\\end{array}\\right) \n",
    "\\end{equation*} \n",
    "où $\\Sigma_X = Cov(X,X)$, $\\Sigma_T = Cov(T,T)$ et $\\Sigma_{X,T} = \\Sigma_{T,X} = Cov(X,T)$. \n",
    "\n",
    "Le complément de Schur du bloc $\\Sigma_X$ est la matrice $\\Sigma S_X = \\Sigma_X - \\Sigma_{X,T}\\Sigma_T^{-1}\\Sigma_{T,X}$.\n",
    "\n",
    "\n",
    "On en déduit ainsi :\n",
    "\n",
    "$$f_{X|T=t}(x) = \\frac{1}{(2\\pi)^{k/2}\\sqrt{\\det (\\Sigma S_X)}}\\exp \\left(-\\frac{1}{2}\\left(x - \\psi(t)\\right)^t \\Sigma S_X^{-1}\\left(x - \\psi(t))\\right)\\right).$$\n",
    "\n",
    "Ce qui est d'autre termes nous dit que la variable $\\mathbf{X|T=t}$ suit une loi gaussienne d'espérance $\\psi(t) = \\psi(x) = E(X|T=t) = m_{X|T=t}= m_{Z|Z_{p}=z} = E(X) + \\Sigma_{X,T}C_{Z_{p}}^{-1}(z-m_{\\mathbf{Z_{p}}})$ et de matrice de covariance $\\Sigma S_X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\n",
    "Si ${Y}=(Y_1,\\dots,Y_p)$ est un vecteur de composantes gaussiennes indépendantes, toutes d'espérance nulle et de variance 1,les $Y_i$ sont donc des variables aléatoires gaussiennes centrées, réduites et indépendantes.\n",
    "    Alors, le vecteur $Z = m + RY$ où $R$ est une matrice $p\\times p$ et $m$ est un vecteur de taille $p$ est gaussien comme combinaison linéaire de variables aléatoires gaussiennes, d'espérance m (par linéarité de l'espérance) et de matrice de covariance $\\Sigma = RR^t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. On va utiliser les étapes suggérées par les questions précédentes.\n",
    "\n",
    "\n",
    "\n",
    "- On connaît $\\mu$, $\\Sigma$ et $T$.\n",
    "- On va alors construire $Z$ tel que $Z = m +RY$ où $m$ est le vecteur colonne de la moyenne (ici constitué uniquement de $\\mu$) et $R$ telle que $\\Sigma = RR^t$.\n",
    "- Comme on a défini $\\mathbf{Z}$ telle que $\\mathbf{Z}$ se décompose sous la forme de $\\mathbf{X}$ et $\\mathbf{T}$, on peut déterminer l'espérance $m_{X|T=t}$ et la matrice de covariance $\\Sigma S_X$ associée.\n",
    "- Enfin, on va appliquer de nouveau le procédé utilisé pour $Z$ tel que $X|(T=t) = m_{X|T=t} + AY$ où $AA^t=\\Sigma S_X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données du problème\n",
    "Conventionnellement, $A$ est l'origine, $B=500$, $N=100$.\n",
    "\n",
    "Les données $$\\begin{array}{c|r}i & z(x_i)\\\\\n",
    "\\hline\n",
    "0 & 0\\\\\n",
    "20 & -4\\\\\n",
    "40 & -12.8\\\\\n",
    "60 & -1\\\\\n",
    "80 & -6.5\\\\\n",
    "100 & 0\\end{array}$$\n",
    "\n",
    "L'espérance de chaque composante du vecteur aléatoire $\\mathbf{Z}$ est donnée par $\\mu=-5.$\n",
    "\n",
    "La fonction $C$ est définie par $$C(h)=\\sigma^2 e^{-|h|/a},$$\n",
    "\n",
    "où $|h|$ correspond à la distance entre deux points, $a=50$ et $\\sigma^2=12$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préambule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement de dépendances\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Discrétisation\n",
    "A=0\n",
    "B=500\n",
    "N=101 #Nombre de points de discrétisation\n",
    "Delta = (B-A)/(N-1)\n",
    "discretization_indexes = np.arange(N)\n",
    "discretization = discretization_indexes*Delta\n",
    "#Paramètres du modèle\n",
    "\n",
    "mu=-5\n",
    "a = 50\n",
    "sigma2 = 12\n",
    "\n",
    "#Données\n",
    "\n",
    "observation_indexes = [0,20,40,60,80,100]\n",
    "depth = np.array([0,-4,-12.8,-1,-6.5,0])\n",
    "\n",
    "#Indices des composantes correspondant aux observations et aux componsantes non observées\n",
    "unknown_indexes=list(set(discretization_indexes)-set(observation_indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "1. Ecrire une fonction qui prend en argument la distance entre les points, le paramètre $a$, et le paramètre $\\sigma^2$, et qui retourne la covariance entre deux points.\n",
    "On pourra fournir une matrice de distance à cette fonction. Dans ce cas, la fonction renverra la matrice de covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise la définition de la covariance associée au vecteur aléatoire $\\mathbf{Z}$ donnée par l'énoncé par  $Cov(Z(x_i), Z(x_j)) = \\sigma_{ij}=C(|x_i-x_j|)$ où $C(h)=\\sigma^2 e^{-|h|/a}$ (on considère que $0 \\leqslant i, j \\leqslant N$ et donc on numérote les coefficients de la matrice de covariance de la même façon).\n",
    "On a alors :\n",
    "$$ Cov(Z(x_i), Z(x_j)) = \\sigma_{ij} = \\sigma^2 e^{-d_{i,j}/a} $$ où $d_{i,j} = |x_i-x_j| = \\Delta|i-j|$ (on ne considère que la distance entre les points sur la longueur et pas sur la profondeur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov(h, a, sigma2):\n",
    "    return(np.exp(-abs(h)/a)*sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.        , 11.52947327],\n",
       "       [11.07739616,  8.71378844]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exemple\n",
    "T = np.array([[0,2], [4,16]])\n",
    "cov(T, a, sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculer la matrice de distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice de distance est définie avec $0 \\leqslant i, j \\leqslant N$, donc sur Python, cela ne pose aucun problème avec le décalage d'indice de 1.\n",
    "On a donc, pour $D$ la matrice de distance avec $d_{i,j}$ ses coefficients :\n",
    "$$ d_{i,j} = |x_i-x_j| = \\Delta|i-j|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   5.,  10., ..., 495., 500., 505.],\n",
       "       [  5.,   0.,   5., ..., 490., 495., 500.],\n",
       "       [ 10.,   5.,   0., ..., 485., 490., 495.],\n",
       "       ...,\n",
       "       [495., 490., 485., ...,   0.,   5.,  10.],\n",
       "       [500., 495., 490., ...,   5.,   0.,   5.],\n",
       "       [505., 500., 495., ...,  10.,   5.,   0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def matricedistance(Delta, N):\n",
    "    D = np.zeros((N, N))\n",
    "    for i in range (N):\n",
    "        for j in range (N):\n",
    "            D[i][j] = Delta*abs(i-j)\n",
    "    return(D)\n",
    "\n",
    "matricedistance(Delta, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculer la matrice de covariance du vecteur $\\mathbf{Z}=(Z(x_0),\\dots,Z(x_N))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice de covariance de $\\mathbf{Z}$ est définie par  $[Cov(Z(x_i), Z(x_j)]_{i,j}) = [\\sigma_{ij}]_{i,j}=[C(|x_i-x_j|)]_{i,j}=[C(d_{i,j})]_{i,j} = C(D)$ (là encore, il n'y apas de problème avec les indices car Python commence à l'index 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.20000000e+01, 1.08580490e+01, 9.82476904e+00, ...,\n",
       "        6.02096185e-04, 5.44799157e-04, 4.92954663e-04],\n",
       "       [1.08580490e+01, 1.20000000e+01, 1.08580490e+01, ...,\n",
       "        6.65419193e-04, 6.02096185e-04, 5.44799157e-04],\n",
       "       [9.82476904e+00, 1.08580490e+01, 1.20000000e+01, ...,\n",
       "        7.35401941e-04, 6.65419193e-04, 6.02096185e-04],\n",
       "       ...,\n",
       "       [6.02096185e-04, 6.65419193e-04, 7.35401941e-04, ...,\n",
       "        1.20000000e+01, 1.08580490e+01, 9.82476904e+00],\n",
       "       [5.44799157e-04, 6.02096185e-04, 6.65419193e-04, ...,\n",
       "        1.08580490e+01, 1.20000000e+01, 1.08580490e+01],\n",
       "       [4.92954663e-04, 5.44799157e-04, 6.02096185e-04, ...,\n",
       "        9.82476904e+00, 1.08580490e+01, 1.20000000e+01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def matricecovariance(N, a, sigma2, Delta):\n",
    "    return cov(matricedistance(Delta, N), a, sigma2)\n",
    "\n",
    "matricecovariance(N, a, sigma2, Delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extraire les 3 matrices de covariance suivantes :\n",
    "\n",
    " * entre les observations\n",
    "\n",
    " * entre les observations et les inconnues\n",
    "\n",
    " * entre les inconnues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par définition, une matrice de covariance Z est symétrique. On va donc seulement se concentrer sur la partie supérieure de Z. On connaît les indices des inconnues et des observations, on va alors pouvoir extraire les matrices de covariance demandées.\n",
    "On remarque que les matrices entre les observations et entre les inconnues sont symétriques (mais pas la matrice entre les observations et les inconnues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_matrices_covariances(C_all, observation_indexes, unknown_indexes):\n",
    "    #On travaille initialement avec des matrices de la même taille que C_all\n",
    "    C_obs_tot = np.zeros(shape=C_all.shape)\n",
    "    C_unk_tot = np.zeros(shape=C_all.shape)\n",
    "    \n",
    "    #On remplies les deux premières avec les indices des tableaux\n",
    "    for i in observation_indexes:\n",
    "        for j in observation_indexes:\n",
    "            C_obs_tot[i][j] = C_all[i][j]\n",
    "    for i in unknown_indexes:\n",
    "        for j in unknown_indexes:\n",
    "            C_unk_tot[i][j] = C_all[i][j]\n",
    "            \n",
    "    #La dernière contient ce qu'il reste\n",
    "    C_obs_unk_tot = C_all - C_obs_tot - C_unk_tot\n",
    "    \n",
    "    #Finalement, on les réduits en supprimant les 0, comme par définition de la fonction C\n",
    "    #la covariance ne peut jamais être nulle\n",
    "    return shrink(C_obs_tot), shrink(C_unk_tot), shrink(C_obs_unk_tot)\n",
    "\n",
    "def shrink(M):\n",
    "    new_M = []\n",
    "    for i in range(M.shape[0]):\n",
    "        L = []\n",
    "        for j in range(M.shape[1]):\n",
    "            if M[i][j] != 0:\n",
    "                L.append(M[i][j])\n",
    "        if len(L) != 0:\n",
    "            new_M.append(L)\n",
    "    return np.array(new_M)\n",
    "\n",
    "C_all = matricecovariance(N, a, sigma2, Delta)\n",
    "C_obs, C_inc, C_obs_unk = extraction_matrices_covariances(C_all, observation_indexes, unknown_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculer l'espérance conditionnelle des composantes non observées connaissant les observations et la représenter avec les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esp_cond(N, mu, depth, C_obs_unk, observation_indexes):\n",
    "    \n",
    "    \n",
    "    l_depth = depth.tolist()\n",
    "    l_cond = cond.tolist()\n",
    "    \n",
    "    for i in range(N):\n",
    "        if i in observation_indexes:\n",
    "            l_moycond.append(l_depth.pop(0))\n",
    "        else:\n",
    "            l_moycond.append(l_cond.pop(0))\n",
    "    return(l_moycond)\n",
    "\n",
    "abscisses = np.arange(0, N)\n",
    "plt.plot(abscisses, esp_cond(N, mu, depth, C_obs_unk, observation_indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Calculer la matrice de covariance conditionnelle et tracer sa diagonale (variance conditionnelle) en fonction de la position. Commenter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Effectuer une simulation conditionnelle. Sur un même graphique, tracer la simulation ainsi que les données et l'espérance conditionnelle. Commenter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Ecrire une fonction qui calcule la longueur du câble en fonction du vecteur des profondeurs et du pas de discrétisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Utiliser cette fonction pour calculer la longueur du câble à partir de 100 simulations. Comparer l'espérance conditionnelle (estimée) de la longueur avec la longueur de l'espérance conditionnelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Représenter la suite $M_n$ des moyennes des longueurs de câbles en fonction du nombre de simulations. Commenter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Représenter l'histogramme des longueurs de câbles générées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Donner un intervalle de confiance à 95% de la longueur du câble par 2 méthodes différentes. Commenter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Donner une estimation de la probabilité que la longueur du câble dépasse 525 m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Reprendre les questions précédentes avec 1000, 10000 puis 100000 simulations. Commenter."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "5ceb69a5bbd14071b254c2439a58ac4b",
   "lastKernelId": "0e923419-c540-42c1-ab5f-d0e05ff4521c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
